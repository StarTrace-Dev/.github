> 星海寻踪开发团队 | `StarTrace Dev Team`

Hi，这里是`StarTrace`的`GitHub`！

---
### 简单介绍
一个专注于AI、软件领域的团队。愿景是：
- 让AI造福全人类，构建`安全`、`有用`、`诚实`、`友善`的AGI/ASI
- 构建中文互联网上的一片净土

<details>
<summary>一些关于AI的思考 from jingyaogong/minimind-v</summary>

> 说实在的，我觉得现在的LLM叫大模型、自回归式模型可能还好……

前一阵研究MiniMind及其衍生项目MiniMind-V，看到README里这段话感觉颇有道理，便摘抄改写下来（原作者：`@jingyaogong`）：

什么叫做Large Language Model (LLM)？
什么叫做大型语言模型 (LLM)？
什么叫做多模态模型？

[「LLM」这个名字不好](https://www.jiqizhixin.com/articles/2024-09-15-3)
大语言模型（LLM）名字虽然带有语言二字，但它们其实与语言关系不大，这只是历史问题，更确切的名字应该是自回归 Transformer 或者其他。LLM 更多是一种统计建模的通用技术，它们主要通过自回归 Transformer 来模拟 token 流，而这些 token 可以代表文本、图片、音频、动作选择、甚至是分子等任何东西。 因此，只要能将问题转化为模拟一系列离散 token 的流程，理论上都可以应用 LLM 来解决。 实际上，随着大型语言模型技术栈的日益成熟，我们可能会看到越来越多的问题被纳入这种建模范式。也就是说，问题固定在使用 LLM 进行『下一个 token 的预测』，只是每个领域中 token 的用途和含义有所不同。

ZJU-LiXi老师同样谈及过类似观点（原话大意如下）： 文本、视频、语音、动作等在人类看来属于「多模态」信号，但所谓的「模态」其实只是人类在信息存储方式上的一种分类概念。 就像.txt和.png文件，虽然在视觉呈现和高级表现形式上有所不同，但它们本质上并没有根本区别。 之所以出现「多模态」这个概念，仅仅是因为人类在不同的感知层面上对这些信号的分类需求。 然而，对于机器来说，无论信号来自何种「模态」，最终它们都只是以一串二进制的「单模态」数字序列来呈现。 机器并不会区分这些信号的模态来源，而只是处理和分析这些序列背后所承载的信息内容。

个人认为**G**enerative **P**retrained **T**ransformer (GPT) 比 **L**arge **L**anguage **M**odel (LLM)更为贴切， 因此本人表达上更习惯用"GPT"去代表LLM/VLM/类GPT架构的系列模型，而非为了蹭OpenAI的热度。

至此，我们可以用一句话总结GPT的所作所为：

GPT模型根据现有token预测输出下一个下下一个下下下一个token ...，直到模型输出结束符；此处的"token"其实**并不需要一定是文本！**

> 对于LLM模型，如果需要理解"图片"，我们只要把"图片"作为对一种特殊的从来没见过的"外国语言"，通过"外语词典"翻译后即可作为特殊的语言输入LLM<br>
> 对于LLM模型，如果需要理解"音频"，我们只要把"音频"作为对一种特殊的从来没见过的"外国语言"，通过"外语词典"翻译后即可作为特殊的语言输入LLM<br>
> ...（以此类推）
</details>

---
> 撰写于 2025-4-5，作者`YHX2010`
